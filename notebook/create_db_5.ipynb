{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# In this data Notebook will be shown how the database for the paper.... has been built and how to include temporal information to static databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We want to include temporal information to forestry interventions, we simply assume that over the rotation length of 100 year there is one thinning every 10 years starting from year 10 and a final felling at year 100 all with same intensity and productivities. It means we just equally distribute  into 10 (9 thinnings + 1 final harvest) time steps of 10 years the itermediate exchanges of the forest management unit process.\n",
    "\n",
    "Note that while we could just create a copy of this activity in the same db and work with this, this is not convenient in the case the database to copy is static database like ecoivent. In this case you should change this database from `static` to `dynamic` with a lost of performances in the calculations that can be relevant for big database. Much better to proceed copying the activity and modify it to a newly created dynamic database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T14:12:01.386874Z",
     "start_time": "2017-06-27T16:12:01.383054+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, \"/media/giuseppec/25F62A4E5FEED162/work/temporalis_update/brightway2-temporalis_last\")\n",
    "#use this one below until \"biogenic_carbon\" module (used in Wood_Decay below) is not updated\n",
    "sys.path.insert(0, \"/media/giuseppec/25F62A4E5FEED162/work/temporalis_update/brightway2-temporalis_tests\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T14:12:02.462955Z",
     "start_time": "2017-06-27T16:12:01.750268+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-27 16:12:01.750268. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "from brightway2 import *\n",
    "from bw2temporalis import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T14:12:04.274818Z",
     "start_time": "2017-06-27T16:12:04.252105+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-27 16:12:04.252105. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "projects.set_current('temporalis_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.217388Z",
     "start_time": "2017-06-14T11:01:08.215196+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.215196. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "# databases.list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "we will be create a db with relative years and we set here the (arbitrary) year 0 as the year of haverst. Which we take as year 0 is actually little relevant since we will be run the analysis  with absoulte dates, it is just important to set correct relative timesteps between the unit processes with temporal informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.235500Z",
     "start_time": "2017-06-14T11:01:08.219623+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.219623. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "yr_harv=0\n",
    "new_db_name='tempo'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " first we need to find the code of the unit process we want to include in the background the temporal data i.e `beam, softwood, raw, air drying to u=20%`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.299782Z",
     "start_time": "2017-06-14T11:01:08.237700+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 2 filtered results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['beam, softwood, raw, air drying to u=20%',\n",
       "  'sawnwood, beam, softwood, raw, dried (u=20%)',\n",
       "  'CH',\n",
       "  '12fabb4b0a9fc33d6f0812186295d724',\n",
       "  'ordinary transforming activity',\n",
       "  'd924d7d0-f579-44b5-92d0-69e61443db2d',\n",
       "  'd924d7d0-f579-44b5-92d0-69e61443db2d_a1a4300c-8440-4eed-8205-24042aad6df7.spold']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.237700. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "db=Database('ecoinvent 3.2 cutoff')\n",
    "\n",
    "[[x['name'],x['reference product'],x['location'],x['code'],x['activity type'],x['activity'],x['filename']] \n",
    " for x in db.search('\"beam, softwood, raw, air drying to u=20%\"', #activity name\n",
    "                    filter = {'location':'ch'}, # CH not working\n",
    "                    proxy=True)] \n",
    "\n",
    "# [[x['name'],x['reference product'],x['location'],x['code'],x['activity type'],x['activity'],x['filename']] \n",
    "#  for x in db.search('\"sawnwood, beam, softwood, raw, dried (u=20%)\"',#reference product name\n",
    "#                     filter = {'location':'ch'}, # CH not working\n",
    "#                     proxy=True)]\n",
    "\n",
    "# db.search('\"beam, softwood, raw, air drying to u=20%\"', #activity name\n",
    "#                     filter = {'location':'ch'}, # CH not working\n",
    "#                     proxy=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we look into its exchanges and we just go back untill we find the one with the forest management interventions. We do it manually with the function below and we go upstream the supply chain intil we find the unit process relative to forest management. This means that iteratively we look into the exchanges of the unit process and change the argument of `db.get` with the unit process we want to explore upstrea. For this can be of help the use of the GUI [Activity-browser](https://docs.brightwaylca.org/advanced-installation.html#activity-browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.308157Z",
     "start_time": "2017-06-14T11:01:08.301940+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beam, softwood, raw, air drying to u=20%', 'sawnwood, beam, softwood, raw, dried (u=20%)', 'CH', '12fabb4b0a9fc33d6f0812186295d724'] :\n",
      "\n",
      "['Transformation, to industrial area', 'biosphere', ('biosphere3', '4624deff-2016-41d4-b2bf-3db8dab88779')]\n",
      "['Water', 'biosphere', ('biosphere3', '075e433b-4be4-448e-9510-9a5029c1ce94')]\n",
      "['Transformation, from unspecified', 'biosphere', ('biosphere3', '29630a65-f38c-48a5-9744-c0121f586640')]\n",
      "['Occupation, industrial area', 'biosphere', ('biosphere3', 'fe9c3a98-a6d2-452d-a9a4-a13e64f1b95b')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.301940. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "a=db.get('12fabb4b0a9fc33d6f0812186295d724')\n",
    "\n",
    "print([a['name'],a['reference product'],a['location'],a['code']],':\\n')\n",
    "for exc in a.exchanges():\n",
    "    if exc['type']=='biosphere':\n",
    "        print([exc['name'],exc['type'],exc['input']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "With the previous step we can obtain the path until `softwood forestry, mixed species, sustainable forest management` that is the unit process we want to modify. \n",
    "\n",
    "P.S: we used a dictioanry below just to make more explicity what each code is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.329549Z",
     "start_time": "2017-06-14T11:01:08.309600+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.309600. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "#the keys are the activities, commented out the reference products. \n",
    "\n",
    "# THE FIRST HAS TO BE CHECKED!!\n",
    "\n",
    "sawn={'beam, softwood, raw, air drying to u=20%': #'sawnwood, beam, softwood, raw, dried (u=20%)', 'CH',\n",
    "        ('ecoinvent 3.2 cutoff', '12fabb4b0a9fc33d6f0812186295d724')}\n",
    "\n",
    "sawn_upstream={\n",
    "'sawing, softwood': #'sawnwood, softwood, raw', 'CH',\n",
    "        ('ecoinvent 3.2 cutoff', 'abb367d014840ef43a947fbd2b75ab5b'),\n",
    "'market for sawlog and veneer log, softwood, measured as solid wood under bark': # 'sawlog and veneer log, softwood, measured as solid wood under bark'\n",
    "        ('ecoinvent 3.2 cutoff', '41ba0faa3437ad2c2fe52b6b8c00857c'),\n",
    "'softwood forestry, mixed species, sustainable forest management': # 'sawlog and veneer log, softwood, measured as solid wood under bark', 'CH'\n",
    "        ('ecoinvent 3.2 cutoff', 'd63bbaea0bba23c6b9f02b946d1e7bf8'),\n",
    "}\n",
    "# forest={'softwood forestry, mixed species, sustainable forest management': # 'sawlog and veneer log, softwood, measured as solid wood under bark', 'CH'\n",
    "#         ('ecoinvent 3.2 cutoff','d63bbaea0bba23c6b9f02b946d1e7bf8')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now with the function below we start from `beam, softwood, raw, air drying to u=20%`  copy and all its exchanges as they are unless they are in the dictioanry `sawn_upstream`. In this case we apply the same approch iteratively untill we do not get to the `softwood forestry, mixed species, sustainable forest management`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.365978Z",
     "start_time": "2017-06-14T11:01:08.332414+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.332414. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "def change_sawn(activity_code):\n",
    "    old_db_name='ecoinvent 3.2 cutoff'\n",
    "    activity=Database(old_db_name).get(activity_code)\n",
    "    new_act=copy.deepcopy(activity.as_dict())\n",
    "    new_act['database']=new_db_name\n",
    "    new_act['exchanges']=[] #empty list of exchanges to add add with for loop below\n",
    "    new_act_key=(new_db_name,new_act['code']) #we just keep same code\n",
    "#     new_act_key=(new_db_name,new_act['name']) #we put name for readibility\n",
    "\n",
    "    down=None\n",
    "    \n",
    "    for exc in activity.exchanges():\n",
    "        if exc['input'] not in sawn_upstream.values() or exc['type']=='production':\n",
    "            data = copy.deepcopy(exc._data)\n",
    "            data['output'] = new_act_key\n",
    "\n",
    "            # Change `input` for production exchanges\n",
    "            if exc['input'] == exc['output']:\n",
    "                data['input'] = new_act_key        \n",
    "            new_act['exchanges'].append(data)\n",
    "        else:\n",
    "            data = copy.deepcopy(exc._data)\n",
    "            data['output'] = new_act_key\n",
    "            #need to change the input \n",
    "            data['input'] = (new_db_name,exc['input'][1]) #if  exc['input'] not in forest.values() else exc['input']\n",
    "#             data['input'] = (new_db_name,exc['name']) #if  exc['input'] not in forest.values() else exc['input']\n",
    "\n",
    "            #add two years delay between harvest and sawnwood productin\n",
    "            if exc['input']==('ecoinvent 3.2 cutoff', '41ba0faa3437ad2c2fe52b6b8c00857c'):\n",
    "                data['temporal distribution']=[(-2,exc['amount'])] #remember python is 0 indexed so range is up to -1             \n",
    "\n",
    "            new_act['exchanges'].append(data)\n",
    "            down=data['input']\n",
    "            \n",
    "    return new_act,down\n",
    "\n",
    "\n",
    "new_db={}\n",
    "key=sawn['beam, softwood, raw, air drying to u=20%']\n",
    "while key != None:\n",
    "    ds,key=change_sawn(key[1])\n",
    "    \n",
    "    new_db[(ds['database'],ds['code'])]=ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-17T11:02:58.169875",
     "start_time": "2017-02-17T11:02:58.166010"
    },
    "deletable": true,
    "editable": true
   },
   "source": [
    " ok, we have copied our the upstram exch now we just take all the tecnosphere exchanges of the copied `softwood forestry, mixed species, sustainable forest management` and spread them over the 100 years of rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.387016Z",
     "start_time": "2017-06-14T11:01:08.367994+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.367994. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "for i,exc in enumerate(new_db[('tempo', 'd63bbaea0bba23c6b9f02b946d1e7bf8')]['exchanges']):\n",
    "    if exc['type']=='technosphere':\n",
    "        new_db[('tempo', 'd63bbaea0bba23c6b9f02b946d1e7bf8')]['exchanges'][i]['temporal distribution']=[(yr,exc['amount']/10) for yr in range(-90,1,10)] #remember python is 0 indexed so range is up to -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Glulam production and its EOL were modelleded separately in Simapro and imported in a separate Bw2 database. Now we will take production and link it to the modified sawnwood with the relative temporal information (i.e. 2 years between sawnood production and glulam). First we search for the dataset with glulam production and EOL. Then we search for the sawnwood exchange in the production dataset, modifies it with the one created above and add this modified dataset and  he copy of the EOL dataset to the database we are creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.422159Z",
     "start_time": "2017-06-14T11:01:08.389010+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['_softwood, primary construction, glulam beam, EOL_wood/ EU U',\n",
       "  '99054f40ae985b96bbdfde3f0043d566'],\n",
       " ['_softwood, primary construction, glulam beam, production_wood/ EU U',\n",
       "  'e2997759fbd9f7e785472c83d56a1db3'],\n",
       " ['_Softwood, Primary construction, glulam beam, Equivalence_EOL/ EU U',\n",
       "  '8bd90a5f050dc85eadc6af6d98d02e59'],\n",
       " ['_Softwood, Primary construction, glulam beam, Equivalence_production/ EU U',\n",
       "  '61ed29b7dab050397e6dcd5367f6f406']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.389010. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "fur=Database('glu')\n",
    "[[x['name'],x['code']] for x in fur.search('glulam')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.428678Z",
     "start_time": "2017-06-14T11:01:08.424224+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.424224. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "glu=fur.get('e2997759fbd9f7e785472c83d56a1db3') #get glulam prod\n",
    "glu_eol=fur.get('99054f40ae985b96bbdfde3f0043d566') #get flulam eol\n",
    "\n",
    "# [[x['name'],x['amount'],x['unit'],x['input']] for x in glu.exchanges()] #look into exchanges of eol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.457447Z",
     "start_time": "2017-06-14T11:01:08.430597+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.430597. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "# for prod\n",
    "new_glu_code='glulam_prod'\n",
    "\n",
    "new_glu=copy.deepcopy(glu.as_dict())\n",
    "new_glu['database']=new_db_name\n",
    "new_glu['code']=new_glu_code\n",
    "new_glu['name']=new_glu_code\n",
    "new_glu['exchanges']=[] #empty list of exchanges to add add with for loop below\n",
    "new_glu_key=(new_db_name,new_glu['code']) #we jsut keep same code and change db for semplicity\n",
    "\n",
    "to_replace=(new_db_name,'12fabb4b0a9fc33d6f0812186295d724')\n",
    "\n",
    "for exc in glu.exchanges():        \n",
    "    data = copy.deepcopy(exc._data)\n",
    "    data['output'] = new_glu_key\n",
    "    # Change `input` for production exchanges\n",
    "    if exc['input'] == exc['output']:\n",
    "        data['input'] = new_glu_key\n",
    "    #change sawnwood\n",
    "    if exc['name']=='_Sawn timber, softwood, raw, kiln dried, u=20%, at plant':\n",
    "        data['input']=to_replace\n",
    "        data['name']=new_db[to_replace]['name']\n",
    "        data['temporal distribution']=[(-2,exc['amount'])]  # sawnwood is produced 2 years before being used by glulam \n",
    "    new_glu['exchanges'].append(data)\n",
    "new_db[new_glu_key]=new_glu\n",
    "# new_glu['exchanges']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-18T17:27:00.480878",
     "start_time": "2017-02-18T17:27:00.475655"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# test to add loop (to del later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.480581Z",
     "start_time": "2017-06-14T11:01:08.461136+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.461136. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "# new_db[('tempo', 'd63bbaea0bba23c6b9f02b946d1e7bf8')]['exchanges'].append({'amount': 0.9,\n",
    "#   'input': new_glu_key,\n",
    "#   'name': new_glu_code,\n",
    "#   'output': ('tempo', 'd63bbaea0bba23c6b9f02b946d1e7bf8'),\n",
    "#   'type': 'technosphere'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.514891Z",
     "start_time": "2017-06-14T11:01:08.482489+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.482489. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "#for eol\n",
    "new_glu_eol_code='glulam_eol'\n",
    "\n",
    "new_glu_eol=copy.deepcopy(glu_eol.as_dict())\n",
    "new_glu_eol['database']=new_db_name\n",
    "new_glu_eol['code']=new_glu_eol_code\n",
    "new_glu_eol['name']=new_glu_eol_code\n",
    "new_glu_eol['exchanges']=[] #empty list of exchanges to add add with for loop below\n",
    "new_glu_key_eol=(new_db_name,new_glu_eol['code']) #we jsut keep same code and change db for semplicity\n",
    "\n",
    "to_replace=(new_db_name,'12fabb4b0a9fc33d6f0812186295d724')\n",
    "\n",
    "for exc in glu_eol.exchanges():        \n",
    "    data = copy.deepcopy(exc._data)\n",
    "    data['output'] = new_glu_key_eol\n",
    "    # Change `input` for production exchanges\n",
    "    if exc['input'] == exc['output']:\n",
    "        data['input'] = new_glu_key_eol\n",
    "    new_glu_eol['exchanges'].append(data)\n",
    "new_db[new_glu_key_eol]=new_glu_eol\n",
    "# new_glu_eol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Good, now we have the the dataset `glulam_prod` with the dynamic inventory of the glulam production,  but `glulam_eol` it is still static and we want that also it dynamic. We assume a mean lifetime $k$ for glulam of 50 years. Being lifetime variable we apply a statistical distribution estimate this decay following the approach of [Marland](http://link.springer.com/article/10.1007/s11027-009-9205-6) and parametrizing the gamma function following  [Cherubini](http://onlinelibrary.wiley.com/doi/10.1111/j.1757-1707.2011.01156.x/abstract) i.e. we transform it to a chisquare distribution (already available in temporalis) using parameters $a = k/2$ and $b = 2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.564483Z",
     "start_time": "2017-06-14T11:01:08.516554+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: object of type <class 'float'> cannot be safely interpreted as an integer.\n",
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.516554. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "from bw2temporalis.dyn_methods.biogenic_carbon import Wood_Decay\n",
    "glu_decay=Wood_Decay.chi2(emission_year=50,t_horizon=500,tstep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.570323Z",
     "start_time": "2017-06-14T11:01:08.566291+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.566291. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "# plt.plot(glu_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Good, now we could modify the `glulam_eol` making its exchanges dynamic, but this would be more complicate and also logically weirder than creating a new dataset, that is actually our Functional Unit, that has input exchange one cubic meter of `glulam_prod` and one m3 of `glulam_eol`, this latter spread over time considering its `glu_decay`. We create manually the FU dataset as below and write the new database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.588279Z",
     "start_time": "2017-06-14T11:01:08.572929+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.572929. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "# del databases['tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.814873Z",
     "start_time": "2017-06-14T11:01:08.591708+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0%   100%\n",
      "[#######] | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 06/14/2017 11:01:08\n",
      "  Finished: 06/14/2017 11:01:08\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 138.00\n",
      "  Memory %: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.591708. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "code_FU='glulam_FU'\n",
    "new_db[(new_db_name,code_FU)]={\n",
    " 'database':new_db_name,\n",
    " 'name':code_FU,\n",
    " 'code':code_FU,\n",
    " 'unit':'cubic meter',\n",
    " 'exchanges': \n",
    "    [{\n",
    "   'amount': 1.0,\n",
    "   'input': (new_db_name, new_glu_code),\n",
    "   'name': new_glu_eol_code,\n",
    "   'type': 'technosphere',\n",
    "   'unit': 'cubic meter'\n",
    "    },{\n",
    "   'amount': 1.0,\n",
    "   'input': (new_db_name, new_glu_eol_code),\n",
    "   'name': new_glu_code,\n",
    "   'temporal distribution': [(yr,val) for yr,val in enumerate(glu_decay)],\n",
    "   'type': 'technosphere',\n",
    "   'unit': 'cubic meter'\n",
    "    }],\n",
    "}\n",
    "\n",
    "tempo = Database(\"tempo\")\n",
    "tempo.write(new_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we just add a tag to some of the processes that will give grouped results for easier interpretation. See `group` in DynanimcLCA class of Temporalis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T14:15:43.830467Z",
     "start_time": "2017-06-27T16:15:43.658426+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-27 16:15:43.658426. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "for x in [  ('tempo', '41ba0faa3437ad2c2fe52b6b8c00857c'),#'market for sawlog and veneer log, softwood, measured as solid wood under bark' (cubic meter, CH, None)\n",
    "            ('tempo', 'abb367d014840ef43a947fbd2b75ab5b'),# 'sawing, softwood'\n",
    "            ('tempo', 'glulam_eol'),\n",
    "            ('tempo', 'glulam_prod'),\n",
    "            ]:\n",
    "    act=get_activity(x)\n",
    "    act['tempo_group'] = True\n",
    "    act.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we show another important thing. As you can see from the database we created when they are registered by default they are dynamic i.e. are evaluated by the graph traversal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.822436Z",
     "start_time": "2017-06-14T11:01:08.817408+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agribalyse 1.3 new biosphere Static:  False (by default)\n",
      "agribalyse 1.3 Static:  True\n",
      "biosphere3 Static:  False (by default)\n",
      "ecoinvent 2.2 Static:  True\n",
      "ecoinvent 3.2 cutoff Static:  True\n",
      "glu Static:  True\n",
      "glu_orig Static:  False (by default)\n",
      "tempo Static:  False (by default)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.817408. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "for db in databases.list:\n",
    "    print(db,'Static: ',databases[db].get('static','False (by default)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you are using a database that does not contain any temporal information you should always set the attribute `static= True` and the flush() to save it as shown below. Despite not obligatory this will sensibly improve your calculation time. And is the same reason why at the beginning of this notebook we suggested to create a new (dynamic) database copying the unit processes needed from ecoinvent rather than create modified copies of the dataset in it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "databases['my_db_name']['static']=True\n",
    "databases.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Good we have created our dynamic database 'tempo' that is linked upstream to several databases (see below). In the next notebook we'll run the analysis and test the performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.840530Z",
     "start_time": "2017-06-14T11:01:08.824443+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'biosphere3', 'ecoinvent 2.2', 'ecoinvent 3.2 cutoff', 'glu', 'tempo'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.824443. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "tempo.find_graph_dependents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:01:08.859795Z",
     "start_time": "2017-06-14T11:01:08.841931+02:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Agribalyse 1.3 new biosphere',\n",
       " 'agribalyse 1.3',\n",
       " 'biosphere3',\n",
       " 'ecoinvent 2.2',\n",
       " 'ecoinvent 3.2 cutoff',\n",
       " 'glu',\n",
       " 'glu_orig',\n",
       " 'tempo']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Interpreting naive datetime as local 2017-06-14 11:01:08.841931. Please add timezone info to timestamps.\n"
     ]
    }
   ],
   "source": [
    "databases.list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
